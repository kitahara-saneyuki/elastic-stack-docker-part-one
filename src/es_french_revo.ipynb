{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "os.environ[\"RABBITMQ_HOST\"] = \"localhost\"\n",
    "\n",
    "from celery_tasks import ingest_data\n",
    "\n",
    "CHUNK_SIZE = 400\n",
    "ES_CHUNK_SIZE = 50\n",
    "INDEX_NAME = \"es_french_revo_idx\"\n",
    "MODEL_ID = \"BAAI/bge-large-zh-v1.5\"\n",
    "MODEL_ID_ES = \"baai__bge-large-zh-v1.5\"\n",
    "MODEL_DIM = 1024\n",
    "MODEL_SIMILARITY = \"cosine\"\n",
    "\n",
    "ES_HOST = \"https://localhost:9200/\"\n",
    "ES_PASS = \"y5AADXZR0l63CvTz1AsWznNiAM1Ukq7KSd3MEra\"\n",
    "# ES_PASS = getpass(\"ElasticSearch Password: \")\n",
    "# COHERE_API_KEY = getpass(\"Elastic Api Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model \\\n",
    "    -u elastic -p $ES_PASS \\\n",
    "    --url $ES_HOST \\\n",
    "    --hub-model-id $MODEL_ID \\\n",
    "    --task-type text_embedding \\\n",
    "    --insecure \\\n",
    "    --clear-previous \\\n",
    "    --start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    # For local development\n",
    "    hosts=[ES_HOST],\n",
    "    basic_auth=('elastic', ES_PASS), \n",
    "    verify_certs=False\n",
    ")\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.delete(index=INDEX_NAME, ignore_unavailable=True)\n",
    "\n",
    "# Setup the index\n",
    "client.indices.create(\n",
    "    index=INDEX_NAME,\n",
    "    mappings={\n",
    "        \"dynamic\": \"true\",\n",
    "        \"properties\": {\n",
    "            \"passages\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"vector\": {\n",
    "                        \"properties\": {\n",
    "                            \"predicted_value\": {\n",
    "                                \"type\": \"dense_vector\",\n",
    "                                \"index\": True,\n",
    "                                \"dims\": MODEL_DIM,\n",
    "                                \"similarity\": MODEL_SIMILARITY,\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some Documents through Celery\n",
    "\n",
    "Now we can add documents with large amounts of text in body_content and automatically have them chunked, and each chunk text embedded into vectors by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read MD File\n",
    "def read_MD(md_file):\n",
    "    f = open(md_file, 'r')\n",
    "    docs = f.read()\n",
    "    # 删除 markdown 标记\n",
    "    docs = re.sub('#+ |\\*+|_+|\\> |\\[\\^[0-9]+\\]|: ', '', docs)\n",
    "    docs = re.sub('\\n *[0-9]+\\. +|\\n- ', '\\n', docs)\n",
    "    # 按自然段分行\n",
    "    docs = re.split('\\n\\n---\\n\\n|\\n\\n|\\n', docs)\n",
    "    # 删除空字符串\n",
    "    docs = list(filter(lambda doc: len(doc) > 0, docs))\n",
    "    title = docs[0]\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"docs\": docs[1:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = '../french_revo'\n",
    "directories = [x[0] for x in os.walk(root_directory) if '.git' not in x[0]]\n",
    "docs = []\n",
    "\n",
    "\n",
    "for directory in directories[1:]:\n",
    "    md_files = [f\"{directory}/{md_file}\" for md_file in os.listdir(directory)]\n",
    "    for md_file in md_files:\n",
    "        read_md = read_MD(md_file)\n",
    "        docs += [{\"text\": doc, \"title\": read_md[\"title\"], \"file\": md_file, \"_index\": INDEX_NAME} for _i, doc in enumerate(read_md[\"docs\"])]\n",
    "\n",
    "print(len(docs))\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the documents to the index directly\n",
    "for i in range(0, len(docs), ES_CHUNK_SIZE):\n",
    "    ingest_data.apply_async(\n",
    "        kwargs={\n",
    "            \"docs\": docs[i: min(i + ES_CHUNK_SIZE, len(docs))]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Pretty printing Elasticsearch responses\n",
    "\n",
    "Your API calls will return hard-to-read nested JSON. We'll create a little function called pretty_response to return nice, human-readable outputs from our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_response(response):\n",
    "    if len(response[\"hits\"][\"hits\"]) == 0:\n",
    "        print(\"Your search returned no results.\")\n",
    "    else:\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            id = hit[\"_id\"]\n",
    "            score = hit[\"_score\"]\n",
    "            doc_title = hit[\"_source\"][\"title\"]\n",
    "            passage_text = \"\"\n",
    "\n",
    "            for passage in hit[\"inner_hits\"][\"passages\"][\"hits\"][\"hits\"]:\n",
    "                passage_text += passage[\"fields\"][\"passages\"][0][\"text\"][0] + \"\\n\\n\"\n",
    "            text = hit[\"_source\"][\"text\"]\n",
    "\n",
    "            pretty_output = f\"ID: {id}\\nDoc Title: {doc_title}\\nText:\\n{text}\\nScore: {score}\"\n",
    "            print(pretty_output)\n",
    "            print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.search(\n",
    "    index=INDEX_NAME,\n",
    "    knn={\n",
    "        \"inner_hits\": {\"size\": 1, \"_source\": False, \"fields\": [\"passages.text\"]},\n",
    "        \"field\": \"passages.vector.predicted_value\",\n",
    "        \"k\": 20,\n",
    "        \"num_candidates\": 100,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": MODEL_ID_ES,\n",
    "                \"model_text\": \"资产阶级由什么样的人群构成？\",\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "[hit[\"_source\"][\"text\"] for hit in response[\"hits\"][\"hits\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
