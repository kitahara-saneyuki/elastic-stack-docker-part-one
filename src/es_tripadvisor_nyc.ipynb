{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Elasticsearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.conda/envs/es_tripadvisor_nyc/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://es01:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"RABBITMQ_HOST\"] = \"localhost\"\n",
    "\n",
    "from celery_tasks import ingest_data_es\n",
    "\n",
    "CHUNK_SIZE = 400\n",
    "ES_CHUNK_SIZE = 1000\n",
    "INDEX_NAME = \"es_tripadvisor_nyc_idx\"\n",
    "MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "MODEL_ID_ES = \"sentence-transformers__all-minilm-l6-v2\"\n",
    "MODEL_DIM = 384\n",
    "MODEL_SIMILARITY = \"dot_product\"\n",
    "\n",
    "ES_HOST = \"https://localhost:9200/\"\n",
    "ES_PASS = getpass(\"ElasticSearch Password: \")\n",
    "COHERE_API_KEY = getpass(\"Elastic Api Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 with Max-Q Design'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'es01', 'cluster_name': 'docker-cluster', 'cluster_uuid': '2d2hAdh2RK2B7QCE92Kbdw', 'version': {'number': '8.13.0', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '09df99393193b2c53d92899662a8b8b3c55b45cd', 'build_date': '2024-03-22T03:35:46.757803203Z', 'build_snapshot': False, 'lucene_version': '9.10.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.conda/envs/es_tripadvisor_nyc/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:399: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n",
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    # For local development\n",
    "    hosts=[ES_HOST],\n",
    "    basic_auth=('elastic', ES_PASS), \n",
    "    verify_certs=False\n",
    ")\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model from hugging face\n",
    "\n",
    "The first thing you will need is a model to create the text embeddings out of the chunks, you can use whatever you would like, but this example will run end to end on the minilm-l6-v2 model. With an Elastic Cloud cluster created or another Elasticsearch cluster ready, we can upload the text embedding model using the eland library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model \\\n",
    "    -u elastic -p $ES_PASS \\\n",
    "    --url $ES_HOST \\\n",
    "    --hub-model-id $MODEL_ID \\\n",
    "    --task-type text_embedding \\\n",
    "    --insecure \\\n",
    "    --clear-previous \\\n",
    "    --start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk and Infer in pipeline\n",
    "\n",
    "The next step is to define an ingest pipeline to break up the text field into chunks of text stored in the passages field. This pipeline has two processors, the first script processor breaks up the text field into an array of sentences stored in the passages field via a regular expression. For further research read up on regular expression advanced features such as negative lookbehind and positive lookbehind to understand how it tries to properly split on sentence boundaries, not split on Mr. or Mrs. or Ms., and keep the punctuation with the sentence. It also tries to concatenate the sentence chunks back together as long as the total string length is under the parameter passed to the script. The next for each processor runs the text embedding model on each sentence via an inference processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the pipeline\n",
    "client.ingest.put_pipeline(\n",
    "    id=\"chunk_text_to_passages\",\n",
    "    processors=[\n",
    "        {\n",
    "            \"script\": {\n",
    "                \"description\": \"Chunk body_content into sentences by looking for . followed by a space\",\n",
    "                \"lang\": \"painless\",\n",
    "                \"source\": \"\"\"\n",
    "          String[] envSplit = /((?<!M(r|s|rs)\\.)(?<=\\.) |(?<=\\!) |(?<=\\?) )/.split(ctx['text']);\n",
    "          ctx['passages'] = new ArrayList();\n",
    "          int i = 0;\n",
    "          boolean remaining = true;\n",
    "          if (envSplit.length == 0) {\n",
    "            return\n",
    "          } else if (envSplit.length == 1) {\n",
    "            Map passage = ['text': envSplit[0]];ctx['passages'].add(passage)\n",
    "          } else {\n",
    "            while (remaining) {\n",
    "              Map passage = ['text': envSplit[i++]];\n",
    "              while (i < envSplit.length && passage.text.length() + envSplit[i].length() < params.model_limit) {passage.text = passage.text + ' ' + envSplit[i++]}\n",
    "              if (i == envSplit.length) {remaining = false}\n",
    "              ctx['passages'].add(passage)\n",
    "            }\n",
    "          }\n",
    "          \"\"\",\n",
    "                \"params\": {\"model_limit\": CHUNK_SIZE},\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"foreach\": {\n",
    "                \"field\": \"passages\",\n",
    "                \"processor\": {\n",
    "                    \"inference\": {\n",
    "                        \"model_id\": MODEL_ID_ES,\n",
    "                        \"input_output\": [\n",
    "                            { \n",
    "                                \"input_field\": \"_ingest._value.text\",\n",
    "                                \"output_field\": \"_ingest._value.vector.predicted_value\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"on_failure\": [\n",
    "                            {\n",
    "                                \"append\": {\n",
    "                                    \"field\": \"_source._ingest.inference_errors\",\n",
    "                                    \"value\": [\n",
    "                                        {\n",
    "                                            \"message\": \"Processor 'inference' in pipeline 'ml-inference-title-vector' failed with message '{{ _ingest.on_failure_message }}'\",\n",
    "                                            \"pipeline\": \"ml-inference-title-vector\",\n",
    "                                            \"timestamp\": \"{{{ _ingest.timestamp }}}\",\n",
    "                                        }\n",
    "                                    ],\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Index\n",
    "\n",
    "Next step is to prepare the mappings to handle the array of sentences and vector objects that will be created during the ingest pipeline. For this particular text embedding model the dimensions are 384 and dot_product similarity will be used for nearest neighbor calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'es_tripadvisor_nyc_idx'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.delete(index=INDEX_NAME, ignore_unavailable=True)\n",
    "\n",
    "# Setup the index\n",
    "client.indices.create(\n",
    "    index=INDEX_NAME,\n",
    "    settings={\"index\": {\"default_pipeline\": \"chunk_text_to_passages\"}},\n",
    "    mappings={\n",
    "        \"dynamic\": \"true\",\n",
    "        \"properties\": {\n",
    "            \"passages\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"vector\": {\n",
    "                        \"properties\": {\n",
    "                            \"predicted_value\": {\n",
    "                                \"type\": \"dense_vector\",\n",
    "                                \"index\": True,\n",
    "                                \"dims\": MODEL_DIM,\n",
    "                                \"similarity\": MODEL_SIMILARITY,\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some Documents through Celery\n",
    "\n",
    "Now we can add documents with large amounts of text in body_content and automatically have them chunked, and each chunk text embedded into vectors by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510463\n"
     ]
    }
   ],
   "source": [
    "file = '../csv/New_York_reviews.csv'\n",
    "\n",
    "#Read CSV File\n",
    "def read_CSV(csv_file):\n",
    "    csv_rows = []\n",
    "    with open(csv_file) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        fields = reader.fieldnames\n",
    "        fields[0] = '_id'\n",
    "        for row in reader:\n",
    "            new_row = {fields[i]:row[fields[i]] for i in range(len(fields))}\n",
    "            new_row['_index'] = INDEX_NAME\n",
    "            new_row['name'] = new_row.pop('review_id')\n",
    "            new_row['text'] = new_row.pop('review_full')\n",
    "            csv_rows.append(new_row)\n",
    "        return csv_rows\n",
    "\n",
    "docs = read_CSV(file)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the documents to the index directly\n",
    "for i in range(0, len(docs), ES_CHUNK_SIZE):\n",
    "    ingest_data.apply_async(\n",
    "        kwargs={\n",
    "            \"docs\": docs[i: min(i + ES_CHUNK_SIZE, len(docs))]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Pretty printing Elasticsearch responses\n",
    "\n",
    "Your API calls will return hard-to-read nested JSON. We'll create a little function called pretty_response to return nice, human-readable outputs from our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_response(response):\n",
    "    if len(response[\"hits\"][\"hits\"]) == 0:\n",
    "        print(\"Your search returned no results.\")\n",
    "    else:\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            id = hit[\"_id\"]\n",
    "            score = hit[\"_score\"]\n",
    "            doc_title = hit[\"_source\"][\"name\"]\n",
    "            restaurant_name = hit[\"_source\"][\"restaurant_name\"]\n",
    "            title_review = hit[\"_source\"][\"title_review\"]\n",
    "            passage_text = \"\"\n",
    "\n",
    "            for passage in hit[\"inner_hits\"][\"passages\"][\"hits\"][\"hits\"]:\n",
    "                passage_text += passage[\"fields\"][\"passages\"][0][\"text\"][0] + \"\\n\\n\"\n",
    "\n",
    "            pretty_output = f\"ID: {id}\\nDoc Title: {doc_title}\\nRestaurant Name: {restaurant_name}\\nTitle Review: {title_review}\\nPassage Text:\\n{passage_text}Score: {score}\"\n",
    "            print(pretty_output)\n",
    "            print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making queries\n",
    "\n",
    "To search the data and return what chunk matched the query best you use inner_hits with the knn clause to return just that best matching chunk of the document in the hits output from the query.\n",
    "\n",
    "Below you will see the response which returns the best document and the most relevant passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 32390\n",
      "Doc Title: review_720045084\n",
      "Restaurant Name: Tony_s_Di_Napoli_Midtown\n",
      "Title Review: Fantastic food!\n",
      "Passage Text:\n",
      "The best pasta in New York! Great dessert and friendly staff. A bit noisy on a Sunday evening but a really nice evening close to Times square.\n",
      "\n",
      "Score: 0.9367155\n",
      "---\n",
      "ID: 109455\n",
      "Doc Title: review_353927840\n",
      "Restaurant Name: Osteria_Morini\n",
      "Title Review: Love their pasta!\n",
      "Passage Text:\n",
      "Hands down the best pasta in NYC - come hungry and skip the bread and apps and just order every pasta on the menu!\n",
      "\n",
      "Score: 0.9235312\n",
      "---\n",
      "ID: 432456\n",
      "Doc Title: review_315314105\n",
      "Restaurant Name: Barbalu_Restaurant\n",
      "Title Review: Delicious food, great atmosphere\n",
      "Passage Text:\n",
      "If you are in NYC and want some good quality, tasty pasta then you have to check this place out.\n",
      "\n",
      "Score: 0.9160058\n",
      "---\n",
      "ID: 138775\n",
      "Doc Title: review_515480340\n",
      "Restaurant Name: Scarpetta\n",
      "Title Review: Amazing Italian\n",
      "Passage Text:\n",
      "The best pasta in the world lives in New York City - Scarpetta!  This restaurant was recommended by one of my friend who lives in the city. He said it’s a nice casual meal in NYC and it’s really good pasta.  We arrived on time at this restaurant but unfortunately the seats wasn’t ready for us. We sat at the bar and have some drinks.\n",
      "\n",
      "Score: 0.91517586\n",
      "---\n",
      "ID: 295216\n",
      "Doc Title: review_680707402\n",
      "Restaurant Name: Aunt_Jake_s_NYC\n",
      "Title Review: Best Pasta in NYC\n",
      "Passage Text:\n",
      "Hands down, the best pasta in New York. Absolutely beautiful food and a hidden gem of a rooftop garden. Service was impeccable, and did I mention the food!?!  You absolutely must eat here if you come and visit. This place should be higher on your 'places to visit' list than Time's square, Liberty Island, Central Park etc.\n",
      "\n",
      "Score: 0.9090612\n",
      "---\n",
      "ID: 52686\n",
      "Doc Title: review_651849097\n",
      "Restaurant Name: Carmine_s_Italian_Restaurant_Times_Square\n",
      "Title Review: Wonderful\n",
      "Passage Text:\n",
      "The best pasta in New York. The only problem is the size of the plates. They must do smaller plates. For one person for example.\n",
      "\n",
      "Score: 0.90883017\n",
      "---\n",
      "ID: 486772\n",
      "Doc Title: review_509284413\n",
      "Restaurant Name: Da_Nico_Ristorante_Manhattan_Location\n",
      "Title Review: Always good\n",
      "Passage Text:\n",
      "It is my go to place in NY for pasta.\n",
      "\n",
      "Score: 0.89932036\n",
      "---\n",
      "ID: 73133\n",
      "Doc Title: review_628690226\n",
      "Restaurant Name: Il_Gattopardo\n",
      "Title Review: Excellence\n",
      "Passage Text:\n",
      "Perhaps the best pasta in NY. They can deliver pasta al dente, as they have done that for us in the past.\n",
      "\n",
      "Score: 0.89915013\n",
      "---\n",
      "ID: 493686\n",
      "Doc Title: review_509987156\n",
      "Restaurant Name: Il_Mulino_New_York_Uptown\n",
      "Title Review: Off the charts good\n",
      "Passage Text:\n",
      "The pasta is the best I have had in the new york area. While everything is great, it is really the pasta that is unmatched. There is a reason why reservations are hard to get and the place is expensive too (yet worth the money). The food here has soul. I have been there more than once and I specially like going in a group of at least 4 so I get to try more items on the menu family style!.\n",
      "\n",
      "Score: 0.89347845\n",
      "---\n",
      "ID: 370122\n",
      "Doc Title: review_180360787\n",
      "Restaurant Name: Coppola_s\n",
      "Title Review: the best restaurant from New York\n",
      "Passage Text:\n",
      "the best chef around new york and the best restaurant from new york....the best pizza , the best steak, the best pasta\n",
      "\n",
      "Score: 0.8884078\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "    index=INDEX_NAME,\n",
    "    knn={\n",
    "        \"inner_hits\": {\"size\": 1, \"_source\": False, \"fields\": [\"passages.text\"]},\n",
    "        \"field\": \"passages.vector.predicted_value\",\n",
    "        \"k\": 20,\n",
    "        \"num_candidates\": 100,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": MODEL_ID_ES,\n",
    "                \"model_text\": \"Best pasta in New York\",\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "pretty_response(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
